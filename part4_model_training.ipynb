{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f679f6c",
   "metadata": {},
   "source": [
    "Part 4: Model Training and Evaluation\n",
    "This script contains the code for the interactive Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd93c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebece41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "import shap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32d9045",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from src.config.config import ModelConfig\n",
    "from src.models.gnn_model import GNNModel\n",
    "from src.models.loss import WeightedMSELoss\n",
    "from src.training.trainer import ModelTrainer\n",
    "from torch_geometric.loader import DataLoader\n",
    "from src.evaluation.evaluator import ModelEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2276d",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def load_graph_data():\n",
    "    \"\"\"Load prepared graph data\"\"\"\n",
    "    data = torch.load('data/graph_data.pt')\n",
    "    print(\"Loaded graph data with features shape:\", data['features'].shape)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a523c30c",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_data_loaders(data, batch_size=32):\n",
    "    \"\"\"Create train/val/test data loaders\"\"\"\n",
    "    # Create indices for splitting\n",
    "    n_samples = len(data['features'])\n",
    "    indices = torch.randperm(n_samples)\n",
    "    \n",
    "    # Split indices\n",
    "    train_size = int(0.7 * n_samples)\n",
    "    val_size = int(0.15 * n_samples)\n",
    "    \n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size+val_size]\n",
    "    test_indices = indices[train_size+val_size:]\n",
    "    \n",
    "    # Create dataset splits\n",
    "    from torch_geometric.data import Data, Dataset\n",
    "    \n",
    "    class GraphDataset(Dataset):\n",
    "        def __init__(self, features, edge_index, targets, indices):\n",
    "            super().__init__()\n",
    "            self.features = features[indices]\n",
    "            self.edge_index = edge_index\n",
    "            self.targets = targets[indices]\n",
    "            self.indices = indices\n",
    "        \n",
    "        def len(self):\n",
    "            return len(self.indices)\n",
    "        \n",
    "        def get(self, idx):\n",
    "            return Data(\n",
    "                x=self.features[idx].unsqueeze(0),\n",
    "                edge_index=self.edge_index,\n",
    "                y=self.targets[idx].unsqueeze(0)\n",
    "            )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = GraphDataset(\n",
    "        data['features'],\n",
    "        data['edge_index'],\n",
    "        data['los_values'],\n",
    "        train_indices\n",
    "    )\n",
    "    \n",
    "    val_dataset = GraphDataset(\n",
    "        data['features'],\n",
    "        data['edge_index'],\n",
    "        data['los_values'],\n",
    "        val_indices\n",
    "    )\n",
    "    \n",
    "    test_dataset = GraphDataset(\n",
    "        data['features'],\n",
    "        data['edge_index'],\n",
    "        data['los_values'],\n",
    "        test_indices\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2515580",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def create_training_progress_plot():\n",
    "    \"\"\"Create interactive plot for training progress\"\"\"\n",
    "    fig = go.FigureWidget()\n",
    "    fig.add_scatter(name=\"Training Loss\")\n",
    "    fig.add_scatter(name=\"Validation Loss\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Training Progress\",\n",
    "        xaxis_title=\"Epoch\",\n",
    "        yaxis_title=\"Loss\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e50e5f",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def train_model_with_visualization(model, train_loader, val_loader, num_epochs=100):\n",
    "    \"\"\"Train model with interactive visualization\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = WeightedMSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Create progress plot\n",
    "    progress_plot = create_training_progress_plot()\n",
    "    display(progress_plot)\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
    "        # Train\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = model(batch.x, batch.edge_index, batch.batch)\n",
    "            loss = criterion(out, batch.y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        train_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                out = model(batch.x, batch.edge_index, batch.batch)\n",
    "                loss = criterion(out, batch.y)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Update progress plot\n",
    "        with progress_plot.batch_update():\n",
    "            progress_plot.data[0].x = list(range(epoch + 1))\n",
    "            progress_plot.data[0].y = train_losses\n",
    "            progress_plot.data[1].x = list(range(epoch + 1))\n",
    "            progress_plot.data[1].y = val_losses\n",
    "    \n",
    "    return model, train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67102b0a",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Evaluate trained model\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch.x, batch.edge_index, batch.batch)\n",
    "            predictions.extend(out.cpu().numpy())\n",
    "            actuals.extend(batch.y.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    \n",
    "    # Create scatter plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=actuals,\n",
    "        y=predictions,\n",
    "        mode='markers',\n",
    "        name='Predictions'\n",
    "    ))\n",
    "    \n",
    "    # Add diagonal line\n",
    "    diagonal = np.linspace(\n",
    "        min(actuals.min(), predictions.min()),\n",
    "        max(actuals.max(), predictions.max()),\n",
    "        100\n",
    "    )\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=diagonal,\n",
    "        y=diagonal,\n",
    "        mode='lines',\n",
    "        name='Perfect Prediction',\n",
    "        line=dict(dash='dash')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Predicted vs Actual Length of Stay',\n",
    "        xaxis_title='Actual Length of Stay',\n",
    "        yaxis_title='Predicted Length of Stay'\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2023d41",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def explain_predictions(model, test_loader, feature_names):\n",
    "    \"\"\"Generate SHAP explanations for model predictions\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    \n",
    "    # Get background data\n",
    "    background_data = next(iter(test_loader)).to(device)\n",
    "    \n",
    "    # Create explainer\n",
    "    explainer = shap.DeepExplainer(model, background_data)\n",
    "    \n",
    "    # Get SHAP values\n",
    "    test_data = next(iter(test_loader)).to(device)\n",
    "    shap_values = explainer.shap_values(test_data)\n",
    "    \n",
    "    # Create summary plot\n",
    "    shap.summary_plot(\n",
    "        shap_values[0],\n",
    "        test_data.x.cpu().numpy(),\n",
    "        feature_names=feature_names,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title('Feature Importance (SHAP)')\n",
    "    \n",
    "    return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48051335",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run model training and evaluation\"\"\"\n",
    "    # Load data\n",
    "    data = load_graph_data()\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(data)\n",
    "    \n",
    "    # Create model\n",
    "    input_dim = data['features'].shape[1]\n",
    "    model = GNNModel(input_dim=input_dim)\n",
    "    \n",
    "    # Train model\n",
    "    trained_model, train_losses, val_losses = train_model_with_visualization(\n",
    "        model, train_loader, val_loader\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    eval_fig = evaluate_model(trained_model, test_loader)\n",
    "    eval_fig.show()\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(trained_model.state_dict(), 'models/trained_gnn.pt')\n",
    "    \n",
    "    print(\"Model training and evaluation complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6723da67",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
