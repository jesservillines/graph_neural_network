{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Part 4: Model Training\n", "\n", "This notebook handles model training and evaluation for the GNN."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import sys\n", "sys.path.append('..')\n", "\n", "import torch\n", "import numpy as np\n", "from torch_geometric.loader import DataLoader\n", "import plotly.graph_objects as go\n", "from tqdm.notebook import tqdm\n", "\n", "from src.models.gnn_model import GNNModel\n", "from src.models.loss import WeightedMSELoss\n", "from src.data.dataset import GraphDataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def load_graph_data():\n", "    \"\"\"Load prepared graph data\"\"\"\n", "    data = torch.load('data/graph_data.pt')\n", "    print(\"\\nLoaded data shapes:\")\n", "    print(f\"Features: {data['features'].shape}\")\n", "    print(f\"Edge index: {data['edge_index'].shape}\")\n", "    print(f\"LOS values: {data['los_values'].shape}\")\n", "    return data"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def create_data_loaders(data, batch_size=32):\n", "    \"\"\"Create train/val/test data loaders\"\"\"\n", "    n_samples = len(data['features'])\n", "    indices = torch.randperm(n_samples)\n", "    \n", "    train_size = int(0.7 * n_samples)\n", "    val_size = int(0.15 * n_samples)\n", "    \n", "    train_indices = indices[:train_size]\n", "    val_indices = indices[train_size:train_size+val_size]\n", "    test_indices = indices[train_size+val_size:]\n", "    \n", "    # Create datasets\n", "    train_dataset = GraphDataset(\n", "        data['features'],\n", "        data['edge_index'],\n", "        data['los_values'],\n", "        train_indices\n", "    )\n", "    \n", "    val_dataset = GraphDataset(\n", "        data['features'],\n", "        data['edge_index'],\n", "        data['los_values'],\n", "        val_indices\n", "    )\n", "    \n", "    test_dataset = GraphDataset(\n", "        data['features'],\n", "        data['edge_index'],\n", "        data['los_values'],\n", "        test_indices\n", "    )\n", "    \n", "    return (\n", "        DataLoader(train_dataset, batch_size=batch_size, shuffle=True),\n", "        DataLoader(val_dataset, batch_size=batch_size),\n", "        DataLoader(test_dataset, batch_size=batch_size)\n", "    )"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    # Load data\n", "    data = load_graph_data()\n", "    \n", "    # Create data loaders\n", "    train_loader, val_loader, test_loader = create_data_loaders(data)\n", "    \n", "    # Create model\n", "    input_dim = data['features'].shape[1]\n", "    model = GNNModel(input_dim=input_dim)\n", "    \n", "    # Rest of training code..."]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": "3"}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.0"}}, "nbformat": 4, "nbformat_minor": 4}