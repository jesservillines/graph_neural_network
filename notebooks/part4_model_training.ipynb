{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f679f6c",
   "metadata": {},
   "source": [
    "Part 4: Model Training and Evaluation\n",
    "This script contains the code for the interactive Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "id": "cfd93c34",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:28:47.770311Z",
     "start_time": "2024-12-03T05:28:47.755331Z"
    }
   },
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "6ebece41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:28:51.668614Z",
     "start_time": "2024-12-03T05:28:50.146481Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import plotly.graph_objects as go\n",
    "from IPython.display import display, HTML\n",
    "import ipywidgets as widgets\n",
    "from tqdm.notebook import tqdm\n",
    "import shap\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "c32d9045",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:43:09.369939Z",
     "start_time": "2024-12-03T05:43:09.352359Z"
    }
   },
   "source": [
    "from src.config.config import ModelConfig\n",
    "from src.models.gnn_model import GNNModel\n",
    "from src.models.loss import WeightedMSELoss\n",
    "from src.training.trainer import ModelTrainer\n",
    "from torch_geometric.loader import DataLoader\n",
    "from src.evaluation.evaluator import ModelEvaluator"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "a8b2276d",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:43:12.136058Z",
     "start_time": "2024-12-03T05:43:12.121651Z"
    }
   },
   "source": [
    "def load_graph_data():\n",
    "    \"\"\"Load prepared graph data\"\"\"\n",
    "    data = torch.load('data/graph_data.pt')\n",
    "    print(\"Loaded graph data with features shape:\", data['features'].shape)\n",
    "    return data"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "a523c30c",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:43:13.293184Z",
     "start_time": "2024-12-03T05:43:13.278670Z"
    }
   },
   "source": [
    "def create_data_loaders(data, batch_size=32):\n",
    "    \"\"\"Create train/val/test data loaders\"\"\"\n",
    "    # Create indices for splitting\n",
    "    n_samples = len(data['features'])\n",
    "    indices = torch.randperm(n_samples)\n",
    "    \n",
    "    # Split indices\n",
    "    train_size = int(0.7 * n_samples)\n",
    "    val_size = int(0.15 * n_samples)\n",
    "    \n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size+val_size]\n",
    "    test_indices = indices[train_size+val_size:]\n",
    "    \n",
    "    # Create dataset splits\n",
    "    from torch_geometric.data import Data, Dataset\n",
    "    \n",
    "    class GraphDataset(Dataset):\n",
    "        def __init__(self, features, edge_index, targets, indices):\n",
    "            super().__init__()\n",
    "            self.features = features[indices]\n",
    "            self.edge_index = edge_index\n",
    "            self.targets = targets[indices]\n",
    "            self.indices = indices\n",
    "        \n",
    "        def len(self):\n",
    "            return len(self.indices)\n",
    "        \n",
    "        def get(self, idx):\n",
    "            return Data(\n",
    "                x=self.features[idx].unsqueeze(0),\n",
    "                edge_index=self.edge_index,\n",
    "                y=self.targets[idx].unsqueeze(0)\n",
    "            )\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = GraphDataset(\n",
    "        data['features'],\n",
    "        data['edge_index'],\n",
    "        data['los_values'],\n",
    "        train_indices\n",
    "    )\n",
    "    \n",
    "    val_dataset = GraphDataset(\n",
    "        data['features'],\n",
    "        data['edge_index'],\n",
    "        data['los_values'],\n",
    "        val_indices\n",
    "    )\n",
    "    \n",
    "    test_dataset = GraphDataset(\n",
    "        data['features'],\n",
    "        data['edge_index'],\n",
    "        data['los_values'],\n",
    "        test_indices\n",
    "    )\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "d2515580",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:43:14.338618Z",
     "start_time": "2024-12-03T05:43:14.323732Z"
    }
   },
   "source": [
    "def create_training_progress_plot():\n",
    "    \"\"\"Create interactive plot for training progress\"\"\"\n",
    "    fig = go.FigureWidget()\n",
    "    fig.add_scatter(name=\"Training Loss\")\n",
    "    fig.add_scatter(name=\"Validation Loss\")\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=\"Training Progress\",\n",
    "        xaxis_title=\"Epoch\",\n",
    "        yaxis_title=\"Loss\",\n",
    "        showlegend=True\n",
    "    )\n",
    "    \n",
    "    return fig"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "a6e50e5f",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:43:15.444186Z",
     "start_time": "2024-12-03T05:43:15.429220Z"
    }
   },
   "source": [
    "def train_model_with_visualization(model, train_loader, val_loader, num_epochs=100):\n",
    "    \"\"\"Train model with interactive visualization\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = model.to(device)\n",
    "    \n",
    "    criterion = WeightedMSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    # Create progress plot\n",
    "    progress_plot = create_training_progress_plot()\n",
    "    display(progress_plot)\n",
    "    \n",
    "    # Training loop\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    for epoch in tqdm(range(num_epochs), desc=\"Training\"):\n",
    "        # Train\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for batch in train_loader:\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            out = model(batch.x, batch.edge_index, batch.batch)\n",
    "            loss = criterion(out, batch.y)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        train_loss = epoch_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        \n",
    "        # Validate\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch = batch.to(device)\n",
    "                out = model(batch.x, batch.edge_index, batch.batch)\n",
    "                loss = criterion(out, batch.y)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "        \n",
    "        # Update progress plot\n",
    "        with progress_plot.batch_update():\n",
    "            progress_plot.data[0].x = list(range(epoch + 1))\n",
    "            progress_plot.data[0].y = train_losses\n",
    "            progress_plot.data[1].x = list(range(epoch + 1))\n",
    "            progress_plot.data[1].y = val_losses\n",
    "    \n",
    "    return model, train_losses, val_losses"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "67102b0a",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:43:16.682717Z",
     "start_time": "2024-12-03T05:43:16.669203Z"
    }
   },
   "source": [
    "def evaluate_model(model, test_loader):\n",
    "    \"\"\"Evaluate trained model\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    \n",
    "    predictions = []\n",
    "    actuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            batch = batch.to(device)\n",
    "            out = model(batch.x, batch.edge_index, batch.batch)\n",
    "            predictions.extend(out.cpu().numpy())\n",
    "            actuals.extend(batch.y.cpu().numpy())\n",
    "    \n",
    "    predictions = np.array(predictions)\n",
    "    actuals = np.array(actuals)\n",
    "    \n",
    "    # Create scatter plot\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=actuals,\n",
    "        y=predictions,\n",
    "        mode='markers',\n",
    "        name='Predictions'\n",
    "    ))\n",
    "    \n",
    "    # Add diagonal line\n",
    "    diagonal = np.linspace(\n",
    "        min(actuals.min(), predictions.min()),\n",
    "        max(actuals.max(), predictions.max()),\n",
    "        100\n",
    "    )\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=diagonal,\n",
    "        y=diagonal,\n",
    "        mode='lines',\n",
    "        name='Perfect Prediction',\n",
    "        line=dict(dash='dash')\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title='Predicted vs Actual Length of Stay',\n",
    "        xaxis_title='Actual Length of Stay',\n",
    "        yaxis_title='Predicted Length of Stay'\n",
    "    )\n",
    "    \n",
    "    return fig"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "b2023d41",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:43:49.167039Z",
     "start_time": "2024-12-03T05:43:49.152514Z"
    }
   },
   "source": [
    "def explain_predictions(model, test_loader, feature_names):\n",
    "    \"\"\"Generate SHAP explanations for model predictions\"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    \n",
    "    # Get background data\n",
    "    background_data = next(iter(test_loader)).to(device)\n",
    "    \n",
    "    # Create explainer\n",
    "    explainer = shap.DeepExplainer(model, background_data)\n",
    "    \n",
    "    # Get SHAP values\n",
    "    test_data = next(iter(test_loader)).to(device)\n",
    "    shap_values = explainer.shap_values(test_data)\n",
    "    \n",
    "    # Create summary plot\n",
    "    shap.summary_plot(\n",
    "        shap_values[0],\n",
    "        test_data.x.cpu().numpy(),\n",
    "        feature_names=feature_names,\n",
    "        show=False\n",
    "    )\n",
    "    plt.title('Feature Importance (SHAP)')\n",
    "    \n",
    "    return plt.gcf()"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "48051335",
   "metadata": {
    "lines_to_next_cell": 1,
    "ExecuteTime": {
     "end_time": "2024-12-03T05:43:52.538610Z",
     "start_time": "2024-12-03T05:43:52.524596Z"
    }
   },
   "source": [
    "def main():\n",
    "    \"\"\"Main function to run model training and evaluation\"\"\"\n",
    "    # Load data\n",
    "    data = load_graph_data()\n",
    "    \n",
    "    # Create data loaders\n",
    "    train_loader, val_loader, test_loader = create_data_loaders(data)\n",
    "    \n",
    "    # Create model\n",
    "    input_dim = data['features'].shape[1]\n",
    "    model = GNNModel(input_dim=input_dim)\n",
    "    \n",
    "    # Train model\n",
    "    trained_model, train_losses, val_losses = train_model_with_visualization(\n",
    "        model, train_loader, val_loader\n",
    "    )\n",
    "    \n",
    "    # Evaluate model\n",
    "    eval_fig = evaluate_model(trained_model, test_loader)\n",
    "    eval_fig.show()\n",
    "    \n",
    "    # Save model\n",
    "    torch.save(trained_model.state_dict(), 'models/trained_gnn.pt')\n",
    "    \n",
    "    print(\"Model training and evaluation complete.\")"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "6723da67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T05:43:53.661097Z",
     "start_time": "2024-12-03T05:43:53.460629Z"
    }
   },
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded graph data with features shape: torch.Size([957, 87])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Tensor' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[13], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m----> 2\u001B[0m     \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[12], line 7\u001B[0m, in \u001B[0;36mmain\u001B[1;34m()\u001B[0m\n\u001B[0;32m      4\u001B[0m data \u001B[38;5;241m=\u001B[39m load_graph_data()\n\u001B[0;32m      6\u001B[0m \u001B[38;5;66;03m# Create data loaders\u001B[39;00m\n\u001B[1;32m----> 7\u001B[0m train_loader, val_loader, test_loader \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_data_loaders\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Create model\u001B[39;00m\n\u001B[0;32m     10\u001B[0m input_dim \u001B[38;5;241m=\u001B[39m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m]\n",
      "Cell \u001B[1;32mIn[7], line 59\u001B[0m, in \u001B[0;36mcreate_data_loaders\u001B[1;34m(data, batch_size)\u001B[0m\n\u001B[0;32m     51\u001B[0m test_dataset \u001B[38;5;241m=\u001B[39m GraphDataset(\n\u001B[0;32m     52\u001B[0m     data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfeatures\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     53\u001B[0m     data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medge_index\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     54\u001B[0m     data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlos_values\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     55\u001B[0m     test_indices\n\u001B[0;32m     56\u001B[0m )\n\u001B[0;32m     58\u001B[0m \u001B[38;5;66;03m# Create data loaders\u001B[39;00m\n\u001B[1;32m---> 59\u001B[0m train_loader \u001B[38;5;241m=\u001B[39m \u001B[43mDataLoader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     60\u001B[0m val_loader \u001B[38;5;241m=\u001B[39m DataLoader(val_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n\u001B[0;32m     61\u001B[0m test_loader \u001B[38;5;241m=\u001B[39m DataLoader(test_dataset, batch_size\u001B[38;5;241m=\u001B[39mbatch_size)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gnn_env\\lib\\site-packages\\torch_geometric\\loader\\dataloader.py:87\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[1;34m(self, dataset, batch_size, shuffle, follow_batch, exclude_keys, **kwargs)\u001B[0m\n\u001B[0;32m     84\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfollow_batch \u001B[38;5;241m=\u001B[39m follow_batch\n\u001B[0;32m     85\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexclude_keys \u001B[38;5;241m=\u001B[39m exclude_keys\n\u001B[1;32m---> 87\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__init__\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[0;32m     88\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     89\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     90\u001B[0m \u001B[43m    \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     91\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcollate_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCollater\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfollow_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexclude_keys\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     92\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gnn_env\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:351\u001B[0m, in \u001B[0;36mDataLoader.__init__\u001B[1;34m(self, dataset, batch_size, shuffle, sampler, batch_sampler, num_workers, collate_fn, pin_memory, drop_last, timeout, worker_init_fn, multiprocessing_context, generator, prefetch_factor, persistent_workers, pin_memory_device)\u001B[0m\n\u001B[0;32m    349\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# map-style\u001B[39;00m\n\u001B[0;32m    350\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m shuffle:\n\u001B[1;32m--> 351\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m \u001B[43mRandomSampler\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgenerator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgenerator\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n\u001B[0;32m    352\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    353\u001B[0m         sampler \u001B[38;5;241m=\u001B[39m SequentialSampler(dataset)  \u001B[38;5;66;03m# type: ignore[arg-type]\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gnn_env\\lib\\site-packages\\torch\\utils\\data\\sampler.py:143\u001B[0m, in \u001B[0;36mRandomSampler.__init__\u001B[1;34m(self, data_source, replacement, num_samples, generator)\u001B[0m\n\u001B[0;32m    140\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement, \u001B[38;5;28mbool\u001B[39m):\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mreplacement should be a boolean value, but got replacement=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mreplacement\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 143\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnum_samples\u001B[49m, \u001B[38;5;28mint\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    144\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnum_samples should be a positive integer value, but got num_samples=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_samples\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gnn_env\\lib\\site-packages\\torch\\utils\\data\\sampler.py:150\u001B[0m, in \u001B[0;36mRandomSampler.num_samples\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    146\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mnum_samples\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mint\u001B[39m:\n\u001B[0;32m    148\u001B[0m     \u001B[38;5;66;03m# dataset size might change at runtime\u001B[39;00m\n\u001B[0;32m    149\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_samples \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 150\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_source\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_samples\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\gnn_env\\lib\\site-packages\\torch_geometric\\data\\dataset.py:274\u001B[0m, in \u001B[0;36mDataset.__len__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    272\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__len__\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mint\u001B[39m:\n\u001B[0;32m    273\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"The number of examples in the dataset.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 274\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mTypeError\u001B[0m: 'Tensor' object is not callable"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "97ce82e48a0fc45d"
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
